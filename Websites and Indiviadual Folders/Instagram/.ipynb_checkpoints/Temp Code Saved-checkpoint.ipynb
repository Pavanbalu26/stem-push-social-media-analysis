{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9175915",
   "metadata": {},
   "outputs": [],
   "source": [
    "from selenium import webdriver\n",
    "from shutil import which\n",
    "from bs4 import BeautifulSoup\n",
    "import re\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from selenium.common.exceptions import NoSuchElementException\n",
    "from selenium.common.exceptions import ElementClickInterceptedException\n",
    "from selenium.common.exceptions import TimeoutException\n",
    "import time  \n",
    "import pandas as pd\n",
    "import requests\n",
    "import wget\n",
    "\n",
    "\n",
    "\n",
    "def extract_likes_and_comments(text):\n",
    "    pattern_likes = r'(\\d+) likes'\n",
    "    pattern_comments = r'(\\d+) comments'\n",
    "\n",
    "    match_likes = re.search(pattern_likes, text)\n",
    "    likes = match_likes.group(1) if match_likes else None\n",
    "\n",
    "    match_comments = re.search(pattern_comments, text)\n",
    "    comments = match_comments.group(1) if match_comments else None\n",
    "\n",
    "    return [likes, comments]\n",
    "\n",
    "\n",
    "#set path for chromedriver extension\n",
    "chrome_path = which('/usr/local/bin/chromedriver')\n",
    "\n",
    "service = Service(executable_path=chrome_path)\n",
    "driver = webdriver.Chrome(service=service)\n",
    "\n",
    "driver.get('https://www.instagram.com/')\n",
    "driver.implicitly_wait(20)\n",
    "\n",
    "#target username\n",
    "username = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='username']\")))\n",
    "password = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"input[name='password']\")))\n",
    "\n",
    "#enter username and password\n",
    "username.clear()\n",
    "username.send_keys(\"pavanbalu26\")\n",
    "password.clear()\n",
    "password.send_keys(\"Rakul@123;;\")\n",
    "\n",
    "#target the login button and click it\n",
    "button = WebDriverWait(driver, 5).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"button[type='submit']\"))).click()\n",
    "\n",
    "#We are logged in!\n",
    "\n",
    "time.sleep(5)\n",
    "try:\n",
    "    alert = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//div[contains(text(), \"Not Now\")]'))).click()\n",
    "except (NoSuchElementException,ElementClickInterceptedException):\n",
    "    pass\n",
    "\n",
    "time.sleep(5)\n",
    "\n",
    "try:\n",
    "    alert2 = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, '//button[contains(text(), \"Not Now\")]'))).click()\n",
    "except (NoSuchElementException,ElementClickInterceptedException,TimeoutException):\n",
    "    pass\n",
    "\n",
    "#target the search input field\n",
    "search_icon = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.CSS_SELECTOR, \"svg[aria-label='Search']\"))).click()\n",
    "time.sleep(5)\n",
    "searchbox = WebDriverWait(driver,10).until(EC.element_to_be_clickable((By.CSS_SELECTOR,\"input[placeholder='Search']\")))\n",
    "\n",
    "\n",
    "workbook = Workbook()\n",
    "time.sleep(4)\n",
    "start = time.time()\n",
    "current_datetime = datetime.datetime.now()\n",
    "formatted_datetime = current_datetime.strftime(\"%Y-%m-%d_%H-%M-%S\")\n",
    "filename = f\"Instagram_{formatted_datetime}.xlsx\"\n",
    "activeSheetNotUsed = True\n",
    "\n",
    "\n",
    "keywordsList =['#Stem Education','#Stem Push']\n",
    "\n",
    "\n",
    "#search for the hashtag STEM EDUCATION\n",
    "searchbox.clear()\n",
    "keyword = \"#STEM EDUCATION\"\n",
    "searchbox.send_keys(keyword)\n",
    "time.sleep(4)\n",
    "searchbox.send_keys(Keys.ENTER)\n",
    "time.sleep(10)\n",
    "searchbox.send_keys(Keys.ENTER)\n",
    "time.sleep(20)\n",
    " \n",
    "# FIXING THE DOUBLE ENTER\n",
    "# time.sleep(5) # Wait for 5 seconds\n",
    "# my_link = WebDriverWait(driver, 10).until(EC.element_to_be_clickable((By.XPATH, \"//a[contains(@href, '/\" + keyword[1:] + \"/')]\")))\n",
    "# my_link.click()\n",
    "\n",
    "#scroll down 2 times\n",
    "#increase the range to sroll more\n",
    "n_scrolls = 0\n",
    "for j in range(0, n_scrolls):\n",
    "    driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "    time.sleep(3)\n",
    "    \n",
    "# #target all the link elements on the page\n",
    "# anchors = driver.find_elements(By.XPATH,\"//a[contains(@href, '/p/')]\")\n",
    "# anchors = [a.get_attribute('href') for a in anchors]\n",
    "# #narrow down all links to image links only\n",
    "# # anchors = [a for a in anchors if str(a).startswith(\"https://www.instagram.com/p/\")]\n",
    "# anchors = [a for a in anchors]\n",
    "\n",
    "anchors = driver.find_elements(By.XPATH,\"//a[contains(@href, '/p/')]\")\n",
    "anchors = [a.get_attribute('href') for a in anchors]\n",
    "anchors = [a for a in anchors]\n",
    "\n",
    "print(anchors)\n",
    "print('Found ' + str(len(anchors)) + ' links to images')\n",
    "\n",
    "\n",
    "\n",
    "for link in anchors:\n",
    "    response = requests.get(link)\n",
    "    html_content = response.content\n",
    "    # Create a BeautifulSoup object with the HTML content\n",
    "    soup = BeautifulSoup(html_content, 'html.parser')\n",
    "\n",
    "    # Find the meta tag with the specified attributes\n",
    "    meta_tag_for_name = soup.find('meta', attrs={'name': 'twitter:title'})\n",
    "    meta_tag_for_desc = soup.find('meta', attrs ={'property' : 'og:title'})\n",
    "    meta_tag_for_additional = soup.find('meta', attrs= {'name': 'description'})\n",
    "    likes,comments = extract_likes_and_comments(meta_tag_for_additional.get('content'))\n",
    "    # Extract the content attribute value\n",
    "    username  = meta_tag_for_name.get('content')\n",
    "    desc = meta_tag_for_desc.get('content')\n",
    "    # Print the extracted content\n",
    "    print('username-->', username.split(\"â€¢\")[0].strip())\n",
    "    print('description-->',desc)\n",
    "    print('likes-->',likes,'comments-->',comments)\n",
    "    print('-----------------------------------------------------------------------------------------------------------')\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "# #follow each image link and extract only image at index=1\n",
    "# t = 1\n",
    "# for a in anchors:\n",
    "#     for a in anchors:\n",
    "#         driver.get(a)\n",
    "#         wait = WebDriverWait(driver, 60)  # Maximum wait time in seconds\n",
    "#         # Wait until the page is fully loaded\n",
    "#         wait = WebDriverWait(driver, 15)  # Maximum wait time in seconds\n",
    "#         wait.until(EC.presence_of_element_located((By.XPATH, \"//a[@class='x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz _acan _acao _acat _acaw _aj1- _a6hd']\")))\n",
    "#         name = driver.find_element(By.XPATH, \"//a[@class='x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz _acan _acao _acat _acaw _aj1- _a6hd']\")\n",
    "# # Locate the element\n",
    "# #     name = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, \"//a[@class = 'x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz _acan _acao _acat _acaw _aj1- _a6hd']\")))\n",
    "#         print('name ->',name.text)\n",
    "#         wait.until(EC.presence_of_element_located((By.XPATH, \"//h1[@class = '_aacl _aaco _aacu _aacx _aad7 _aade']\")))\n",
    "#         content = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, \"//h1[@class = '_aacl _aaco _aacu _aacx _aad7 _aade']\")))\n",
    "#         print('content -->',content.text)\n",
    "#         try:\n",
    "#             likes = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, \"//span[@class='x193iq5w xeuugli x1fj9vlw x13faqbe x1vvkbs xt0psk2 x1i0vuye xvs91rp x1s688f x5n08af x10wh9bi x1wdrske x8viiok x18hxmgj']/span\")))\n",
    "#             print('likes-->',likes.text)\n",
    "#         except (NoSuchElementException):\n",
    "#             pass\n",
    "#         if t ==10:\n",
    "#             break\n",
    "#         print('------------------------------------------------------------------------------------------------->')\n",
    "\n",
    "    \n",
    "    \n",
    "#     driver.get(a)\n",
    "#     time.sleep(20)\n",
    "#     name = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, \"//a[@class = 'x1i10hfl xjbqb8w x6umtig x1b1mbwd xaqea5y xav7gou x9f619 x1ypdohk xt0psk2 xe8uvvx xdj266r x11i5rnm xat24cr x1mh8g0r xexx8yu x4uap5 x18d9i69 xkhd6sd x16tdsg8 x1hl2dhg xggy1nq x1a2a7pz _acan _acao _acat _acaw _aj1- _a6hd']\")))\n",
    "#     print('name ->',name.text)\n",
    "#     content = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, \"//h1[@class = '_aacl _aaco _aacu _aacx _aad7 _aade']\")))\n",
    "#     print('content -->',content.text)\n",
    "#     try:\n",
    "#         likes = WebDriverWait(driver, 15).until(EC.element_to_be_clickable((By.XPATH, \"//span[@class='x193iq5w xeuugli x1fj9vlw x13faqbe x1vvkbs xt0psk2 x1i0vuye xvs91rp x1s688f x5n08af x10wh9bi x1wdrske x8viiok x18hxmgj']/span\")))\n",
    "#         print('likes-->',likes.text)\n",
    "#     except (NoSuchElementException):\n",
    "#         pass\n",
    "#     if t ==10:\n",
    "#         break\n",
    "#     print('------------------------------------------------------------------------------------------------->')\n",
    "\n",
    "#     time.sleep(10)\n",
    "#     img = driver.find_elements(By.TAG_NAME,'img')\n",
    "#     img = [i.get_attribute('src') for i in img]\n",
    "#     images.append(img[1])\n",
    "    \n",
    "# images[:5]    \n",
    "\n",
    "# import os\n",
    "# import wget\n",
    "# path = os.getcwd()\n",
    "# path = os.path.join(path, keyword[1:] + \"s\")\n",
    "\n",
    "# #create the directory\n",
    "# os.mkdir(path)\n",
    "\n",
    "# path\n",
    "\n",
    "# #download images\n",
    "# counter = 0\n",
    "# for image in images:\n",
    "#     save_as = os.path.join(path, keyword[1:] + str(counter) + '.jpg')\n",
    "#     wget.download(image, save_as)\n",
    "#     counter += 1\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
